{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef2027b",
   "metadata": {},
   "source": [
    "WEBSCRAPING ASSIGNMENT - 2 (using selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb23c7",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "1 normal method and 1 method by defining function shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16dd6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries, will be useful for all 10 program\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce042083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assistant Manager/Manager - Data Analyst - Ana...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Data Analyst - WFH</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                                Senior Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                        HCL hiring For Data Analyst   \n",
       "4                              Customer Data Analyst   \n",
       "5                                   Sr. Data Analyst   \n",
       "6                             Data Analyst - FinTech   \n",
       "7  Assistant Manager/Manager - Data Analyst - Ana...   \n",
       "8                          Python Data Analyst - WFH   \n",
       "9                    Data Analyst - Decision Science   \n",
       "\n",
       "                                   Company_name  \\\n",
       "0                                     TeamLease   \n",
       "1                                         Optum   \n",
       "2                             Artech infosystem   \n",
       "3                              HCL Technologies   \n",
       "4                                        Oracle   \n",
       "5       Global Indian School Education Services   \n",
       "6                                  Primo Hiring   \n",
       "7                     Huquo Consulting Pvt. Ltd   \n",
       "8  hCapital Business Consulting Private Limited   \n",
       "9                       Jana Small Finance Bank   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0                                Bangalore/Bengaluru             5-8 Yrs  \n",
       "1                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-6 Yrs  \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai             3-8 Yrs  \n",
       "4                                Bangalore/Bengaluru             1-3 Yrs  \n",
       "5                          Bangalore/Bengaluru, Pune            6-11 Yrs  \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-2 Yrs  \n",
       "7                   Bangalore/Bengaluru, Delhi / NCR            6-11 Yrs  \n",
       "8                                             Remote             4-9 Yrs  \n",
       "9                                Bangalore/Bengaluru             3-8 Yrs  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com') #calling webdriver and getting into website\n",
    "    \n",
    "desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "desig.send_keys('Data Analyst') #Entering required input in job search field \n",
    "loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys('Bangalore') #Input of location data for search\n",
    "search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "search.click() #clicking search button\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "driver.close() #Closing the web browser after scraping\n",
    "\n",
    "jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "# saving data into a data frame\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2015a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for scraping the data\n",
    "def job_details(url):\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url) #calling webdriver and getting into website\n",
    "\n",
    "    desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "    desig.send_keys('Data Analyst') #Entering required input in job search field \n",
    "    loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "    loc.send_keys('Bangalore') #Input of location data for search\n",
    "    search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "    search.click() #clicking search button\n",
    "\n",
    "    title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "    experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "    exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "    loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "    driver.close() #Closing the web browser after scraping\n",
    "\n",
    "    jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "    # saving data into a data frame\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9681569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assistant Manager/Manager - Data Analyst - Ana...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Data Analyst - WFH</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                                Senior Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                        HCL hiring For Data Analyst   \n",
       "4                              Customer Data Analyst   \n",
       "5                                   Sr. Data Analyst   \n",
       "6                             Data Analyst - FinTech   \n",
       "7  Assistant Manager/Manager - Data Analyst - Ana...   \n",
       "8                          Python Data Analyst - WFH   \n",
       "9                    Data Analyst - Decision Science   \n",
       "\n",
       "                                   Company_name  \\\n",
       "0                                     TeamLease   \n",
       "1                                         Optum   \n",
       "2                             Artech infosystem   \n",
       "3                              HCL Technologies   \n",
       "4                                        Oracle   \n",
       "5       Global Indian School Education Services   \n",
       "6                                  Primo Hiring   \n",
       "7                     Huquo Consulting Pvt. Ltd   \n",
       "8  hCapital Business Consulting Private Limited   \n",
       "9                       Jana Small Finance Bank   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0                                Bangalore/Bengaluru             5-8 Yrs  \n",
       "1                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-6 Yrs  \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai             3-8 Yrs  \n",
       "4                                Bangalore/Bengaluru             1-3 Yrs  \n",
       "5                          Bangalore/Bengaluru, Pune            6-11 Yrs  \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-2 Yrs  \n",
       "7                   Bangalore/Bengaluru, Delhi / NCR            6-11 Yrs  \n",
       "8                                             Remote             4-9 Yrs  \n",
       "9                                Bangalore/Bengaluru             3-8 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details('https://www.naukri.com') #calling the function to scrape data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f9c04",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1067e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring Data Science Intern - DataTrained Educa...</td>\n",
       "      <td>DataTrained</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>SMARTPADDLE TECHNOLOGY PVT. LTD.</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "6  Hiring Data Science Intern - DataTrained Educa...   \n",
       "7                                  Lead ML Scientist   \n",
       "8                      Tcs Hiring For Data Scientist   \n",
       "9                                Data Scientist - II   \n",
       "\n",
       "                                  Company_name  \\\n",
       "0                                Tech Mahindra   \n",
       "1                                   CitiusTech   \n",
       "2                                    Accenture   \n",
       "3  NTT DATA Business Solutions Private Limited   \n",
       "4                                       upGrad   \n",
       "5                                    Accenture   \n",
       "6                                  DataTrained   \n",
       "7                            Fractal Analytics   \n",
       "8              TATA CONSULTANCY SERVICES (TCS)   \n",
       "9             SMARTPADDLE TECHNOLOGY PVT. LTD.   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...             4-9 Yrs  \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune             5-9 Yrs  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...             6-8 Yrs  \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...             4-9 Yrs  \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             0-2 Yrs  \n",
       "5                                Bangalore/Bengaluru             4-6 Yrs  \n",
       "6  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...             0-2 Yrs  \n",
       "7                        Bangalore/Bengaluru, Mumbai            6-10 Yrs  \n",
       "8   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)             3-8 Yrs  \n",
       "9     Bangalore/Bengaluru, India, Mumbai (All Areas)             3-6 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com') #calling webdriver and getting into website\n",
    "    \n",
    "desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "desig.send_keys('Data Scientist') #Entering required input in job search field \n",
    "loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys('Bangalore') #Input of location data for search\n",
    "search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "search.click() #clicking search button\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "driver.close() #Closing the web browser after scraping\n",
    "\n",
    "jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "# saving data into a data frame\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33463df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details('https://www.naukri.com')\n",
    "#calling the function to scrape data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2a8df",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5a6639d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist, Associate</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Job-title             Company_name  \\\n",
       "0                         Data Scientist              GlobalLogic   \n",
       "1        DigitalBCG GAMMA Data Scientist  Boston Consulting Group   \n",
       "2                         Data Scientist                    Optum   \n",
       "3    Data Scientist / Chat-bot Developer             Big Seo Buzz   \n",
       "4                    Lead Data Scientist  R Systems International   \n",
       "5  Data Scientist - Predictive Analytics             Confidential   \n",
       "6               Knowledge/Data Scientist  BOLD Technology Systems   \n",
       "7                         Data Scientist           Feedback Infra   \n",
       "8                         Data Scientist                   4i Odc   \n",
       "9              Data Scientist, Associate            NatWest Group   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru            8-10 Yrs  \n",
       "1                     New Delhi, Bangalore/Bengaluru             2-5 Yrs  \n",
       "2                                   Gurgaon/Gurugram             2-7 Yrs  \n",
       "3  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             3-7 Yrs  \n",
       "4                             Noida(Sector-59 Noida)            7-10 Yrs  \n",
       "5  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...             1-6 Yrs  \n",
       "6                                        Delhi / NCR             3-6 Yrs  \n",
       "7                                   Gurgaon/Gurugram             2-4 Yrs  \n",
       "8                                              Noida             2-4 Yrs  \n",
       "9                                        Delhi / NCR             2-7 Yrs  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com') #calling webdriver and getting into website\n",
    "    \n",
    "desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "desig.send_keys('Data Scientist') #Entering required input in job search field \n",
    "search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "search.click() #clicking search button\n",
    "\n",
    "for i in range(5): #applying location filter \"Delhi/NCR\"\n",
    "    try:\n",
    "        box = driver.find_element_by_xpath(\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")\n",
    "        driver.execute_script(\"arguments[0].click();\", box)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "        \n",
    "for i in range(5): #applying salary filter \"3-6 lakhs\"\n",
    "    try:\n",
    "        box = driver.find_element_by_xpath(\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")\n",
    "        driver.execute_script(\"arguments[0].click();\", box)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "driver.close() #Closing the web browser after scraping\n",
    "\n",
    "jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "# saving data into a data frame\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659ac14",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bc7db7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (Free Size)</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "      <td>₹1,128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Polarized, UV Protection Wayfarer Sunglasses (61)</td>\n",
       "      <td>₹197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Over-sized ...</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                            Product   Price\n",
       "0   ROZZETTA CRAFT       UV Protection Cat-eye Sunglasses (Free Size)    ₹359\n",
       "1    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)  ₹1,128\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799\n",
       "3    VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...    ₹901\n",
       "4   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹449\n",
       "..             ...                                                ...     ...\n",
       "95   VINCENT CHASE             UV Protection Wayfarer Sunglasses (50)  ₹1,049\n",
       "96            SRPM  Polarized, UV Protection Wayfarer Sunglasses (61)    ₹197\n",
       "97       ROYAL SON  UV Protection, Gradient Butterfly, Over-sized ...    ₹559\n",
       "98          AISLIN  by Lenskart Polarized, UV Protection Wayfarer ...    ₹576\n",
       "99   VINCENT CHASE  UV Protection, Gradient Retro Square Sunglasse...  ₹1,049\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com') #calling webdriver and getting into website  \n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click() #closing login pop-up\n",
    "driver.find_element_by_xpath(\"//input[@name='q']\").send_keys('sunglasses') #Entering required input in product search field\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking search button\n",
    "time.sleep(3)\n",
    "Brand = []\n",
    "Product = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    brand = [i.text for i in brand] # Scraping of brand data\n",
    "    prod = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    product = [i.text for i in prod] # Scraping of product name data\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    price = [i.text for i in price] # Scraping of product price data\n",
    "    \n",
    "    Brand.extend(brand) #Updating brand data scraped from current page to a list\n",
    "    Product.extend(product) #Updating product data scraped from current page to a list\n",
    "    Price.extend(price) #Updating price data scraped from current page to a list\n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH, \"//*[text()='Next']\") #Navigating to next page\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "Data = pd.DataFrame({'Brand':Brand[0:100], 'Product':Product[0:100], 'Price':Price[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919a79f",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d0097e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It is better to buy iPhone 11 over iPhone 12 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>It was amazing experience for me. Honestly i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I bought iPhone 11 On March 2021, And I am Wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it.\\nThis phone is really amazing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating               Review  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5            Excellent   \n",
       "97      5             Terrific   \n",
       "98      5            Excellent   \n",
       "99      5               Super!   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  It is better to buy iPhone 11 over iPhone 12 i...  \n",
       "96  It was amazing experience for me. Honestly i a...  \n",
       "97  I bought iPhone 11 On March 2021, And I am Wri...  \n",
       "98  Just go for it.\\nThis phone is really amazing....  \n",
       "99  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com') #calling webdriver and getting into website\n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click() #closing login pop-up\n",
    "driver.find_element_by_xpath(\"//input[@name='q']\").send_keys('iphone 11') #Entering required input in product search field\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking search button\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath(\"//a[@class='_1fQZEK']\").click() #Clicking on phone or product to check review\n",
    "\n",
    "p = driver.current_window_handle #get first child window\n",
    "chwd = driver.window_handles\n",
    "for w in chwd: #switch focus to child window\n",
    "    if(w!=p):\n",
    "        driver.switch_to.window(w)\n",
    "        \n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click() #Clicking show all reviews\n",
    "time.sleep(3)\n",
    "Rating = []\n",
    "Review = []\n",
    "Review_full = []\n",
    "start = 0\n",
    "end = 11\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    rating_tags = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rating = [i.text for i in rating_tags] # Scraping of rating data\n",
    "    review_tags = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    review = [i.text for i in review_tags] # Scraping of product review data\n",
    "    review_full_tags = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    review_full = [i.text for i in review_full_tags] # Scraping of product full review data \n",
    "    Rating.extend(rating) #Updating rating data scraped from current page to a list\n",
    "    Review.extend(review) #Updating product review scraped from current page to a list\n",
    "    Review_full.extend(review_full) #Updating full review data scraped from current page to a list\n",
    "    try: #Moving to next page\n",
    "        next_button = driver.find_element(By.XPATH, \"//*[text()='Next']\")\n",
    "        next_button.click()\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "    time.sleep(4) \n",
    "Data = pd.DataFrame({'Rating':Rating[0:100], 'Review':Review[0:100], 'Full review':Review_full[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc36045",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e7ef91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹653</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TR</td>\n",
       "      <td>Breathable, Walking, Running, Casual, Gym Shoe...</td>\n",
       "      <td>₹295</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Casuals, Canvas, Partywear Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Pacer Fire Sneakers For Men</td>\n",
       "      <td>₹1,199</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Men's Fashion Trend Sneakers Sneakers For Men</td>\n",
       "      <td>₹1,919</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>₹333</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Real Bliss</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹395</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹1,099</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                            Product   Price  \\\n",
       "0          SFR  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹653   \n",
       "1       BRUTON                                   Sneakers For Men    ₹499   \n",
       "2       Labbin                                   Sneakers For Men    ₹499   \n",
       "3           TR  Breathable, Walking, Running, Casual, Gym Shoe...    ₹295   \n",
       "4       Shozie        Casuals, Canvas, Partywear Sneakers For Men    ₹379   \n",
       "..         ...                                                ...     ...   \n",
       "95    RED TAPE                        Pacer Fire Sneakers For Men  ₹1,199   \n",
       "96        PUMA      Men's Fashion Trend Sneakers Sneakers For Men  ₹1,919   \n",
       "97   Deals4you  Stylish & Trending Outdoor Walking Comfortable...    ₹333   \n",
       "98  Real Bliss  Casual , Partywear Sneakers Shoes For Men's An...    ₹395   \n",
       "99    RED TAPE                                 Sneakers For Women  ₹1,099   \n",
       "\n",
       "   Discount  \n",
       "0   67% off  \n",
       "1   85% off  \n",
       "2   50% off  \n",
       "3   80% off  \n",
       "4   62% off  \n",
       "..      ...  \n",
       "95  75% off  \n",
       "96  45% off  \n",
       "97  66% off  \n",
       "98  60% off  \n",
       "99  75% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com') #calling webdriver and getting into website  \n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click() #closing login pop-up\n",
    "driver.find_element_by_xpath(\"//input[@name='q']\").send_keys('sneakers') #Entering required input in product search field\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking search button\n",
    "time.sleep(3)\n",
    "Brand = []\n",
    "Product = []\n",
    "Discount = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    brand = [i.text for i in brand] # Scraping of brand data\n",
    "    product = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    product = [i.text for i in product] # Scraping of product name data\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    price = [i.text for i in price] # Scraping of product price data\n",
    "    discount = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    discount = [i.text for i in discount] # Scraping of discount or offer data\n",
    "    \n",
    "    Brand.extend(brand) #Updating brand data scraped from current page to a list\n",
    "    Product.extend(product) #Updating product data scraped from current page to a list\n",
    "    Price.extend(price) #Updating price data scraped from current page to a list\n",
    "    Discount.extend(discount)\n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH, \"//*[text()='Next']\") #Navigating to next page\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "Data = pd.DataFrame({'Brand':Brand[0:100], 'Product':Product[0:100], 'Price':Price[0:100],'Discount':Discount[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c429a",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b6622edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1619Rs. 5399(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Softride Rift Breeze</td>\n",
       "      <td>Rs. 3249Rs. 6499(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eego Italy</td>\n",
       "      <td>Men Trekking Shoes</td>\n",
       "      <td>Rs. 987Rs. 2599(62% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 1077Rs. 1099(2% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Revolution 5 Running Shoes</td>\n",
       "      <td>Rs. 3510Rs. 3695(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AfroJack</td>\n",
       "      <td>Women Colourblocked Sneakers</td>\n",
       "      <td>Rs. 799Rs. 3995(80% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Women Fly Sneakers</td>\n",
       "      <td>Rs. 1504Rs. 4299(65% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 658Rs. 1198(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Mystere Running Shoes</td>\n",
       "      <td>Rs. 3599Rs. 4799(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 3299Rs. 5499(40% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand                         Product  \\\n",
       "0                Red Tape               Men Walking Shoes   \n",
       "1                    Puma            Softride Rift Breeze   \n",
       "2              Eego Italy              Men Trekking Shoes   \n",
       "3                   Sparx               Men Running Shoes   \n",
       "4                    Nike  Men Revolution 5 Running Shoes   \n",
       "..                    ...                             ...   \n",
       "95               AfroJack    Women Colourblocked Sneakers   \n",
       "96  HRX by Hrithik Roshan              Women Fly Sneakers   \n",
       "97             HIGHLANDER       Men Woven Design Sneakers   \n",
       "98                 ADIDAS       Men Mystere Running Shoes   \n",
       "99                   Puma               Men Running Shoes   \n",
       "\n",
       "                        Price  \n",
       "0   Rs. 1619Rs. 5399(70% OFF)  \n",
       "1   Rs. 3249Rs. 6499(50% OFF)  \n",
       "2    Rs. 987Rs. 2599(62% OFF)  \n",
       "3    Rs. 1077Rs. 1099(2% OFF)  \n",
       "4    Rs. 3510Rs. 3695(5% OFF)  \n",
       "..                        ...  \n",
       "95   Rs. 799Rs. 3995(80% OFF)  \n",
       "96  Rs. 1504Rs. 4299(65% OFF)  \n",
       "97   Rs. 658Rs. 1198(45% OFF)  \n",
       "98  Rs. 3599Rs. 4799(25% OFF)  \n",
       "99  Rs. 3299Rs. 5499(40% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.myntra.com/shoes') #calling webdriver and getting into website  \n",
    "time.sleep(2)\n",
    "for i in range(5): #Set Price filter to second one\n",
    "    try:\n",
    "        box1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/input')\n",
    "        driver.execute_script(\"arguments[0].click();\", box1)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "time.sleep(2)        \n",
    "for i in range(5): #Set Price Color filter to “Black”\n",
    "    try:\n",
    "        box2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "        driver.execute_script(\"arguments[0].click();\", box2)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "time.sleep(2)\n",
    "\n",
    "Brand = []\n",
    "Product = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 2\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    brand = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    brand = [i.text for i in brand] # Scraping of brand data\n",
    "    prod = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    product = [i.text for i in prod] # Scraping of product name data\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    price = [i.text for i in price] # Scraping of product price data\n",
    "    \n",
    "    Brand.extend(brand) #Updating brand data scraped from current page to a list\n",
    "    Product.extend(product) #Updating product data scraped from current page to a list\n",
    "    Price.extend(price) #Updating price data scraped from current page to a list\n",
    "    \n",
    "    driver.find_element_by_xpath('//li[@class=\"pagination-next\"]').click() #Navigate to next page\n",
    "    time.sleep(3) \n",
    "Data = pd.DataFrame({'Brand':Brand[0:100], 'Product':Product[0:100], 'Price':Price[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f296bd",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import required libraries\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.amazon.in/')\n",
    "#calling webdriver and getting into website\n",
    "\n",
    "product_search = browser.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product_search.send_keys('Laptop')\n",
    "#Entering required input in product search field\n",
    "\n",
    "search = browser.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()\n",
    "#clicking search button\n",
    "\n",
    "browser.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span').click()\n",
    "#browser.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/span').click() #for i9 category\n",
    "#While applying i7 and i9 filter it was found that amazn website not allow simultaneous selection of both selections simultaneously\n",
    "\n",
    "title = []\n",
    "rating = []\n",
    "price = []\n",
    "\n",
    "title_tags = browser.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in title_tags:\n",
    "    title.append(i.text) \n",
    "\n",
    "price_tags = browser.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in price_tags:\n",
    "    price.append(i.text) \n",
    "    \n",
    "rating_tags = browser.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for i in rating_tags:\n",
    "    rating.append(i.get_attribute('aria-label'))\n",
    "#scraping all the required data by xpath route\n",
    "\n",
    "laptops = pd.DataFrame({'Title':title[0:10], 'Price':price[0:10], 'Rating':rating[0:10]})\n",
    "#saving data into a data frame\n",
    "laptops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0212be5",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99426bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#import required libraries\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.ambitionbox.com/')\n",
    "#calling webdriver and getting into website\n",
    "\n",
    "job = browser.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "job.click()\n",
    "#clicking job button\n",
    "\n",
    "search_field = browser.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "search_field.send_keys('Data Scientist')\n",
    "#Entering required input in job search field\n",
    "\n",
    "search = browser.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\")\n",
    "search.click()\n",
    "#clicking search button\n",
    "time.sleep(2)\n",
    "\n",
    "browser.find_element_by_xpath(\"//div[@title='Location']\").click()\n",
    "search_loc = browser.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "search_loc.send_keys('Noida')\n",
    "#Entering required input in location filter\n",
    "time.sleep(2)\n",
    "\n",
    "select_loc = browser.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "select_loc.click()\n",
    "#Clicking location\n",
    "\n",
    "title = []\n",
    "comp = []\n",
    "loc = []\n",
    "exp = []\n",
    "\n",
    "def Noida_jobs():\n",
    "#defining a function to scrape data\n",
    "    title_tags = browser.find_elements_by_xpath(\"//a[@class='title noclick']\")\n",
    "    for i in title_tags:\n",
    "        title.append(i.text) \n",
    "\n",
    "    company_tags = browser.find_elements_by_xpath(\"//p[@class='company body-medium']\")\n",
    "    for i in company_tags:\n",
    "        comp.append(i.text) \n",
    "\n",
    "    experienc_tags = browser.find_elements_by_xpath(\"//p[@class='body-small-l']\")\n",
    "    for i in experienc_tags:\n",
    "        if ('years') in i.text:\n",
    "            exp.append(i.text)\n",
    "        elif ('Yrs') in i.text:\n",
    "            exp.append(i.text) \n",
    "    #scraping all the required data by xpath route\n",
    "        \n",
    "    return(pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Experience_required':exp[0:10]}))\n",
    "    # saving data into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Noida_jobs()\n",
    "#calling the function to scrape data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0eb287",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aaeba42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#import required libraries\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.ambitionbox.com/')\n",
    "#calling webdriver and getting into website\n",
    "\n",
    "browser.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\").click()\n",
    "#clicking salaries button\n",
    "\n",
    "browser.find_element_by_id(\"jobProfileSearchbox\").send_keys(\"Data Scientist\")\n",
    "browser.find_element_by_id(\"jobProfileSearchbox\").click()\n",
    "#Entering required input in job search field\n",
    "time.sleep(5)\n",
    "\n",
    "comp = []\n",
    "record = []\n",
    "exp = []\n",
    "sal = []\n",
    "mi = []\n",
    "ma = []\n",
    "av = []\n",
    "\n",
    "def Data_scientist():\n",
    "#defining a function to scrape data\n",
    "    comp_tags = browser.find_elements_by_xpath(\"//div[@class='name']/a\")\n",
    "    for i in comp_tags:\n",
    "        comp.append(i.text) \n",
    "\n",
    "    record_tags = browser.find_elements_by_xpath(\"//div[@class='name']/span\")\n",
    "    for i in record_tags:\n",
    "        record.append(i.text) \n",
    "\n",
    "    exp_tags = browser.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "    for i in exp_tags:\n",
    "        i = i.text\n",
    "        head, sep, tail = i.partition('\\n . \\n')\n",
    "        exp.append(tail)\n",
    "\n",
    "    sal_tags = browser.find_elements_by_xpath(\"//div[@class='salary-values']/div\")\n",
    "    for i in sal_tags:\n",
    "        sal.append(i.text) \n",
    "    salary = sal[-20:]\n",
    "    for i in range(0,20,2):\n",
    "        mi.append(salary[i])\n",
    "        i = i+1\n",
    "        ma.append(salary[i])\n",
    "\n",
    "    av_tags = browser.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
    "    for i in av_tags:\n",
    "        av.append(i.text) \n",
    "    #scraping all the required data by xpath route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d35bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_scientist()\n",
    "#calling the function to scrape data\n",
    "\n",
    "Data_scientist_salary = pd.DataFrame({'Company':comp, 'No. of salaries recorded':record, 'Work experience':exp, 'Average salary':av[-10:], 'Minimum salary':mi, 'Maximum salary':ma})\n",
    "#saving data as dataframe\n",
    "\n",
    "Data_scientist_salary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
