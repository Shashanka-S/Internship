{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef2027b",
   "metadata": {},
   "source": [
    "WEBSCRAPING ASSIGNMENT - 2 (using selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb23c7",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúSkill, Designations, Companies‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "1 normal method and 1 method by defining function shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48cd50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries, will be useful for all 10 program\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ce042083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assistant Manager/Manager - Data Analyst - Ana...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Data Analyst - WFH</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                                Senior Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                        HCL hiring For Data Analyst   \n",
       "4                              Customer Data Analyst   \n",
       "5                                   Sr. Data Analyst   \n",
       "6                             Data Analyst - FinTech   \n",
       "7  Assistant Manager/Manager - Data Analyst - Ana...   \n",
       "8                          Python Data Analyst - WFH   \n",
       "9                    Data Analyst - Decision Science   \n",
       "\n",
       "                                   Company_name  \\\n",
       "0                                     TeamLease   \n",
       "1                                         Optum   \n",
       "2                             Artech infosystem   \n",
       "3                              HCL Technologies   \n",
       "4                                        Oracle   \n",
       "5       Global Indian School Education Services   \n",
       "6                                  Primo Hiring   \n",
       "7                     Huquo Consulting Pvt. Ltd   \n",
       "8  hCapital Business Consulting Private Limited   \n",
       "9                       Jana Small Finance Bank   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0                                Bangalore/Bengaluru             5-8 Yrs  \n",
       "1                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-6 Yrs  \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai             3-8 Yrs  \n",
       "4                                Bangalore/Bengaluru             1-3 Yrs  \n",
       "5                          Bangalore/Bengaluru, Pune            6-11 Yrs  \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-2 Yrs  \n",
       "7                   Bangalore/Bengaluru, Delhi / NCR            6-11 Yrs  \n",
       "8                                             Remote             4-9 Yrs  \n",
       "9                                Bangalore/Bengaluru             3-8 Yrs  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com') #calling webdriver and getting into website\n",
    "    \n",
    "desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "desig.send_keys('Data Analyst') #Entering required input in job search field \n",
    "loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys('Bangalore') #Input of location data for search\n",
    "search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "search.click() #clicking search button\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "driver.close() #Closing the web browser after scraping\n",
    "\n",
    "jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "# saving data into a data frame\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb7a1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for scraping the data\n",
    "def job_details(url):\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url) #calling webdriver and getting into website\n",
    "\n",
    "    desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "    desig.send_keys('Data Analyst') #Entering required input in job search field \n",
    "    loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "    loc.send_keys('Bangalore') #Input of location data for search\n",
    "    search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "    search.click() #clicking search button\n",
    "\n",
    "    title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "    experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "    exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "    loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "    driver.close() #Closing the web browser after scraping\n",
    "\n",
    "    jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "    # saving data into a data frame\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9681569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Python/Artificial Intelligence</td>\n",
       "      <td>iMindYourBusiness</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Encora</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Opportunity_to_work_with_top_MNC - Data Analys...</td>\n",
       "      <td>NIFTEL COMMUNICATIONS PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SDNA Global</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, New Delhi, Hyder...</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Online / eCommerce</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Chennai,...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                                Senior Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3      Data Analyst - Python/Artificial Intelligence   \n",
       "4                                       Data Analyst   \n",
       "5                             Data Analyst - FinTech   \n",
       "6                             Data Analyst - FinTech   \n",
       "7  Opportunity_to_work_with_top_MNC - Data Analys...   \n",
       "8                                       Data Analyst   \n",
       "9                  Data Analyst - Online / eCommerce   \n",
       "\n",
       "                            Company_name  \\\n",
       "0                              TeamLease   \n",
       "1                                  Optum   \n",
       "2                      Artech infosystem   \n",
       "3                      iMindYourBusiness   \n",
       "4                                 Encora   \n",
       "5                           Primo Hiring   \n",
       "6                           Primo Hiring   \n",
       "7  NIFTEL COMMUNICATIONS PRIVATE LIMITED   \n",
       "8                            SDNA Global   \n",
       "9                           Primo Hiring   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0                                Bangalore/Bengaluru             5-8 Yrs  \n",
       "1                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-6 Yrs  \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...             0-2 Yrs  \n",
       "4                                Bangalore/Bengaluru             3-6 Yrs  \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...             1-2 Yrs  \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-2 Yrs  \n",
       "7                                Bangalore/Bengaluru            7-12 Yrs  \n",
       "8  Bangalore/Bengaluru, Kolkata, New Delhi, Hyder...            5-10 Yrs  \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, Chennai,...             3-6 Yrs  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details('https://www.naukri.com') #calling the function to scrape data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f9c04",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, Companies‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1067e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>LIGHTHOUSE SEARCH (OPC) PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science/ ML freshers</td>\n",
       "      <td>CliqHR Recruitment Services</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring Data Science Intern - DataTrained Educa...</td>\n",
       "      <td>DataTrained</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Visakhap...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                              Senior Data Scientist   \n",
       "5                          Data Science/ ML freshers   \n",
       "6                       Data Scientist/AIML Engineer   \n",
       "7  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "8  Hiring Data Science Intern - DataTrained Educa...   \n",
       "9                  Data Scientist - Engine Algorithm   \n",
       "\n",
       "                                  Company_name  \\\n",
       "0                                Tech Mahindra   \n",
       "1                                   CitiusTech   \n",
       "2                                    Accenture   \n",
       "3  NTT DATA Business Solutions Private Limited   \n",
       "4      LIGHTHOUSE SEARCH (OPC) PRIVATE LIMITED   \n",
       "5                  CliqHR Recruitment Services   \n",
       "6                                       upGrad   \n",
       "7                                    Accenture   \n",
       "8                                  DataTrained   \n",
       "9                                 Primo Hiring   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...             4-9 Yrs  \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune             5-9 Yrs  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...             6-8 Yrs  \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...             4-9 Yrs  \n",
       "4            Bangalore/Bengaluru, Mumbai (All Areas)             2-7 Yrs  \n",
       "5  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             0-1 Yrs  \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             0-2 Yrs  \n",
       "7                                Bangalore/Bengaluru             4-6 Yrs  \n",
       "8  Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...             0-2 Yrs  \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, Visakhap...             1-3 Yrs  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com') #calling webdriver and getting into website\n",
    "    \n",
    "desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "desig.send_keys('Data Scientist') #Entering required input in job search field \n",
    "loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys('Bangalore') #Input of location data for search\n",
    "search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "search.click() #clicking search button\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "driver.close() #Closing the web browser after scraping\n",
    "\n",
    "jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "# saving data into a data frame\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2a8df",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c6b6f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Avantive Solutions</td>\n",
       "      <td>Noida</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Job-title             Company_name  \\\n",
       "0                         Data Scientist              GlobalLogic   \n",
       "1        DigitalBCG GAMMA Data Scientist  Boston Consulting Group   \n",
       "2                         Data Scientist                    Optum   \n",
       "3    Data Scientist / Chat-bot Developer             Big Seo Buzz   \n",
       "4                    Lead Data Scientist  R Systems International   \n",
       "5  Data Scientist - Predictive Analytics             Confidential   \n",
       "6                         Data Scientist       Avantive Solutions   \n",
       "7               Knowledge/Data Scientist  BOLD Technology Systems   \n",
       "8                         Data Scientist           Feedback Infra   \n",
       "9                         Data Scientist                   4i Odc   \n",
       "\n",
       "                                        Job-location Experience_required  \n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru            8-10 Yrs  \n",
       "1                     New Delhi, Bangalore/Bengaluru             2-5 Yrs  \n",
       "2                                   Gurgaon/Gurugram             2-7 Yrs  \n",
       "3  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             3-7 Yrs  \n",
       "4                             Noida(Sector-59 Noida)            7-10 Yrs  \n",
       "5  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...             1-6 Yrs  \n",
       "6                                              Noida            7-10 Yrs  \n",
       "7                                        Delhi / NCR             3-6 Yrs  \n",
       "8                                   Gurgaon/Gurugram             2-4 Yrs  \n",
       "9                                              Noida             2-4 Yrs  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com') #calling webdriver and getting into website\n",
    "    \n",
    "desig = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "desig.send_keys('Data Scientist') #Entering required input in job search field \n",
    "search = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\")\n",
    "search.click() #clicking search button\n",
    "\n",
    "for i in range(5): #applying location filter \"Delhi/NCR\"\n",
    "    try:\n",
    "        box = driver.find_element_by_xpath(\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")\n",
    "        driver.execute_script(\"arguments[0].click();\", box)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "        \n",
    "for i in range(5): #applying salary filter \"3-6 lakhs\"\n",
    "    try:\n",
    "        box = driver.find_element_by_xpath(\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")\n",
    "        driver.execute_script(\"arguments[0].click();\", box)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title = [i.text for i in title_tags] #scraping title data by xpath\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp = [i.text for i in company_tags] #scraping company name data by xpath\n",
    "experienc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp = [i.text for i in experienc_tags] #scraping experience data by xpath\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "loc = [i.text for i in location_tags] #scraping location data by xpath\n",
    "driver.close() #Closing the web browser after scraping\n",
    "\n",
    "jobs = pd.DataFrame({'Job-title':title[0:10], 'Company_name':comp[0:10], 'Job-location':loc[0:10], 'Experience_required':exp[0:10]})   \n",
    "# saving data into a data frame\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659ac14",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter ‚Äúsunglasses‚Äù in the search field where ‚Äúsearch for products, brands andmore‚Äù is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the ‚ÄúNext‚Äù Button at the bottom ofthe page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8028bc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>‚Çπ901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>‚Çπ443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>‚Çπ319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Wayfar...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>‚Çπ213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>‚Çπ669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection, Gradient, Riding Gla...</td>\n",
       "      <td>‚Çπ1,049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                            Product   Price\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ‚Çπ799\n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...    ‚Çπ901\n",
       "2   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ‚Çπ449\n",
       "3           AISLIN  UV Protection, Gradient Butterfly, Retro Squar...    ‚Çπ443\n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ‚Çπ319\n",
       "..             ...                                                ...     ...\n",
       "95       ROYAL SON  UV Protection, Riding Glasses, Mirrored Wayfar...    ‚Çπ599\n",
       "96  kingsunglasses                   Mirrored Aviator Sunglasses (55)    ‚Çπ213\n",
       "97       ROYAL SON       UV Protection Aviator Sunglasses (Free Size)    ‚Çπ339\n",
       "98        Fastrack  by Lenskart Polarized, UV Protection Cat-eye S...    ‚Çπ669\n",
       "99   VINCENT CHASE  Polarized, UV Protection, Gradient, Riding Gla...  ‚Çπ1,049\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com') #calling webdriver and getting into website  \n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click() #closing login pop-up\n",
    "driver.find_element_by_xpath(\"//input[@name='q']\").send_keys('sunglasses') #Entering required input in product search field\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking search button\n",
    "time.sleep(3)\n",
    "Brand = []\n",
    "Product = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    brand = [i.text for i in brand] # Scraping of brand data\n",
    "    prod = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    product = [i.text for i in prod] # Scraping of product name data\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    price = [i.text for i in price] # Scraping of product price data\n",
    "    \n",
    "    Brand.extend(brand) #Updating brand data scraped from current page to a list\n",
    "    Product.extend(product) #Updating product data scraped from current page to a list\n",
    "    Price.extend(price) #Updating price data scraped from current page to a list\n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH, \"//*[text()='Next']\") #Navigating to next page\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Brand':Brand[0:100], 'Product':Product[0:100], 'Price':Price[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919a79f",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "856b906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Very excited to have this phone. This phone ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera üì∏ And Display touching very N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Its Very awesome product working and good came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Best and amazing product.....phone looks so pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent camera and display touching very nic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                 Review  \\\n",
       "0       5         Simply awesome   \n",
       "1       5       Perfect product!   \n",
       "2       5    Best in the market!   \n",
       "3       5     Highly recommended   \n",
       "4       5      Worth every penny   \n",
       "..    ...                    ...   \n",
       "95      5                Awesome   \n",
       "96      5  Mind-blowing purchase   \n",
       "97      5      Terrific purchase   \n",
       "98      5         Classy product   \n",
       "99      5              Brilliant   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Very excited to have this phone. This phone ha...  \n",
       "96  Excellent camera üì∏ And Display touching very N...  \n",
       "97  Its Very awesome product working and good came...  \n",
       "98  Best and amazing product.....phone looks so pr...  \n",
       "99  Excellent camera and display touching very nic...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com') #calling webdriver and getting into website\n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click() #closing login pop-up\n",
    "driver.find_element_by_xpath(\"//input[@name='q']\").send_keys('iphone 11') #Entering required input in product search field\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking search button\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath(\"//a[@class='_1fQZEK']\").click() #Clicking on phone or product to check review\n",
    "\n",
    "p = driver.current_window_handle #get first child window\n",
    "chwd = driver.window_handles\n",
    "for w in chwd: #switch focus to child window\n",
    "    if(w!=p):\n",
    "        driver.switch_to.window(w)\n",
    "time.sleep(3)        \n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click() #Clicking show all reviews\n",
    "time.sleep(3)\n",
    "Rating = []\n",
    "Review = []\n",
    "Review_full = []\n",
    "start = 0\n",
    "end = 11\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    rating_tags = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rating = [i.text for i in rating_tags] # Scraping of rating data\n",
    "    review_tags = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    review = [i.text for i in review_tags] # Scraping of product review data\n",
    "    review_full_tags = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    review_full = [i.text for i in review_full_tags] # Scraping of product full review data \n",
    "    Rating.extend(rating) #Updating rating data scraped from current page to a list\n",
    "    Review.extend(review) #Updating product review scraped from current page to a list\n",
    "    Review_full.extend(review_full) #Updating full review data scraped from current page to a list\n",
    "    try: #Moving to next page\n",
    "        next_button = driver.find_element(By.XPATH, \"//*[text()='Next']\")\n",
    "        next_button.click()\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "    time.sleep(4) \n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Rating':Rating[0:100], 'Review':Review[0:100], 'Full review':Review_full[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc36045",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for ‚Äúsneakers‚Äù in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7ef91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFR</td>\n",
       "      <td>CAMP DENVER Sneakers For Men</td>\n",
       "      <td>‚Çπ653</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ1,849</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>‚Çπ396</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Breathable, Walking, Running, Casual, Gym Shoe...</td>\n",
       "      <td>‚Çπ199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>‚Çπ215</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Airland</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>‚Çπ645</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ394</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>SOLFER PLUS Sneakers For Men</td>\n",
       "      <td>‚Çπ1,789</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ359</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                            Product  \\\n",
       "0               SFR                       CAMP DENVER Sneakers For Men   \n",
       "1            CAMPUS                                   Sneakers For Men   \n",
       "2            Labbin                              supr Sneakers For Men   \n",
       "3          Magnolia  Breathable, Walking, Running, Casual, Gym Shoe...   \n",
       "4            Layasa                                   Sneakers For Men   \n",
       "..              ...                                                ...   \n",
       "95  U.S. POLO ASSN.  Kwik FIT casual sneaker shoes and partywear sh...   \n",
       "96          Airland  Stylish & Trending Outdoor Walking Comfortable...   \n",
       "97            Sparx                                   Sneakers For Men   \n",
       "98           Layasa                       SOLFER PLUS Sneakers For Men   \n",
       "99           ADIDAS                                   Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ‚Çπ653  67% off  \n",
       "1   ‚Çπ1,849   7% off  \n",
       "2     ‚Çπ396  60% off  \n",
       "3     ‚Çπ199  80% off  \n",
       "4     ‚Çπ379  62% off  \n",
       "..     ...      ...  \n",
       "95    ‚Çπ215  24% off  \n",
       "96    ‚Çπ645  60% off  \n",
       "97    ‚Çπ394  55% off  \n",
       "98  ‚Çπ1,789  82% off  \n",
       "99    ‚Çπ359  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.flipkart.com') #calling webdriver and getting into website  \n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click() #closing login pop-up\n",
    "driver.find_element_by_xpath(\"//input[@name='q']\").send_keys('sneakers') #Entering required input in product search field\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking search button\n",
    "time.sleep(3)\n",
    "Brand = []\n",
    "Product = []\n",
    "Discount = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    brand = [i.text for i in brand] # Scraping of brand data\n",
    "    product = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    product = [i.text for i in product] # Scraping of product name data\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    price = [i.text for i in price] # Scraping of product price data\n",
    "    discount = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    discount = [i.text for i in discount] # Scraping of discount or offer data\n",
    "    \n",
    "    Brand.extend(brand) #Updating brand data scraped from current page to a list\n",
    "    Product.extend(product) #Updating product data scraped from current page to a list\n",
    "    Price.extend(price) #Updating price data scraped from current page to a list\n",
    "    Discount.extend(discount)\n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH, \"//*[text()='Next']\") #Navigating to next page\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Brand':Brand[0:100], 'Product':Product[0:100], 'Price':Price[0:100],'Discount':Discount[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c429a",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set second Price filter and Color filter to ‚ÄúBlack‚Äù, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include ‚ÄúBrand‚Äù of the shoes , Short Shoe description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2a72cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Sports Shoes</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Niteball II Sneakers</td>\n",
       "      <td>Rs. 9349Rs. 10999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>Rs. 13295Rs. 13995(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "      <td>Rs. 10799Rs. 11999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women Solar Glide 5 Running</td>\n",
       "      <td>Rs. 9799Rs. 13999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women SL20.3 Running Shoes</td>\n",
       "      <td>Rs. 7799Rs. 11999(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>W omen TriBase Reign 4 Running</td>\n",
       "      <td>Rs. 8399Rs. 11999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women Adizero Adios 7 Run Shoe</td>\n",
       "      <td>Rs. 9599Rs. 11999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                         Product  \\\n",
       "0               Nike  Men ZOOM WINFLO8 Running Shoes   \n",
       "1           Skechers                Men Sports Shoes   \n",
       "2   ADIDAS Originals        Men Niteball II Sneakers   \n",
       "3               Nike    Men React Infinity 3 Running   \n",
       "4   ADIDAS Originals   Men Leather Niteball Sneakers   \n",
       "..               ...                             ...   \n",
       "95            ADIDAS     Women Solar Glide 5 Running   \n",
       "96            ADIDAS      Women SL20.3 Running Shoes   \n",
       "97      UNDER ARMOUR  W omen TriBase Reign 4 Running   \n",
       "98            ADIDAS  Women Adizero Adios 7 Run Shoe   \n",
       "99         J.FONTINI    Men Textured Leather Loafers   \n",
       "\n",
       "                          Price  \n",
       "0      Rs. 7880Rs. 8295(5% OFF)  \n",
       "1                      Rs. 8499  \n",
       "2    Rs. 9349Rs. 10999(15% OFF)  \n",
       "3    Rs. 13295Rs. 13995(5% OFF)  \n",
       "4   Rs. 10799Rs. 11999(10% OFF)  \n",
       "..                          ...  \n",
       "95   Rs. 9799Rs. 13999(30% OFF)  \n",
       "96   Rs. 7799Rs. 11999(35% OFF)  \n",
       "97   Rs. 8399Rs. 11999(30% OFF)  \n",
       "98   Rs. 9599Rs. 11999(20% OFF)  \n",
       "99                     Rs. 7990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.myntra.com/shoes') #calling webdriver and getting into website  \n",
    "time.sleep(2)\n",
    "for i in range(5): #Set Price filter to second one\n",
    "    try:\n",
    "        box1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/input')\n",
    "        driver.execute_script(\"arguments[0].click();\", box1)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "time.sleep(2)        \n",
    "for i in range(5): #Set Price Color filter to ‚ÄúBlack‚Äù\n",
    "    try:\n",
    "        box2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "        driver.execute_script(\"arguments[0].click();\", box2)\n",
    "    except NoSuchElementException as e:\n",
    "        time.sleep(1)\n",
    "time.sleep(2)\n",
    "\n",
    "Brand = []\n",
    "Product = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 2\n",
    "for page in range(start, end): #Scraping multiple pages data\n",
    "    brand = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    brand = [i.text for i in brand] # Scraping of brand data\n",
    "    prod = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    product = [i.text for i in prod] # Scraping of product name data\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    price = [i.text for i in price] # Scraping of product price data\n",
    "    \n",
    "    Brand.extend(brand) #Updating brand data scraped from current page to a list\n",
    "    Product.extend(product) #Updating product data scraped from current page to a list\n",
    "    Price.extend(price) #Updating price data scraped from current page to a list\n",
    "    \n",
    "    driver.find_element_by_xpath('//li[@class=\"pagination-next\"]').click() #Navigate to next page\n",
    "    time.sleep(3) \n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Brand':Brand[0:100], 'Product':Product[0:100], 'Price':Price[0:100]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f296bd",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon.\n",
    "Then set CPU Type filter to ‚ÄúIntel Core i7‚Äù and ‚ÄúIntel Core i9‚Äù\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d1919661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell New G15 5520 Gaming Laptop, Intel i7-1270...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>1,44,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>23,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-i...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>41,690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.8 out of 5 stars   \n",
       "1  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  4.3 out of 5 stars   \n",
       "2  MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...  3.5 out of 5 stars   \n",
       "3  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5 stars   \n",
       "4  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "5  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...  3.9 out of 5 stars   \n",
       "6  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  4.3 out of 5 stars   \n",
       "7  Dell New G15 5520 Gaming Laptop, Intel i7-1270...  4.6 out of 5 stars   \n",
       "8  (Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...  3.6 out of 5 stars   \n",
       "9  (Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-i...  4.1 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    77,990  \n",
       "1    82,990  \n",
       "2    54,990  \n",
       "3    80,990  \n",
       "4    59,990  \n",
       "5    62,990  \n",
       "6    82,990  \n",
       "7  1,44,600  \n",
       "8    23,997  \n",
       "9    41,690  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.amazon.in/') #calling webdriver and getting into website  \n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\").send_keys('Laptop') #Entering product in search field\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div\").click() #Clicking the search button\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span').click() #Filter for i7 category \n",
    "time.sleep(2)\n",
    "title = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "Title = [i.text for i in title] # Scraping of title data\n",
    "rating = driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span[1]\")\n",
    "Rating = [i.get_attribute('aria-label') for i in rating] # Scraping of product rating data\n",
    "price = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "Price = [i.text for i in price] # Scraping of product price data\n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Title':Title[0:10], 'Rating':Rating[0:10], 'Price':Price[0:10]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0212be5",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of ‚ÄúSearch by Designations, Companies, Skills‚Äù enter ‚ÄúData Scientist‚Äù and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of ‚ÄúSearch location‚Äù enter ‚ÄúNoida‚Äù and select location ‚ÄúNoida‚Äù.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99426bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No of days ago job posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2-7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One97 Communications Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company name Rating  \\\n",
       "0  Optum Global Solutions (India) Private Limited    4.1   \n",
       "1  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED    4.3   \n",
       "2                                          EY GDS    3.8   \n",
       "3               GLOBALLOGIC INDIA PRIVATE LIMITED    4.0   \n",
       "4                   GENPACT India Private Limited    4.0   \n",
       "5                                         Genpact    4.0   \n",
       "6        Ericsson India Global Services Pvt. Ltd.    4.3   \n",
       "7                         Dew Solutions Pvt. Ltd.    4.3   \n",
       "8                    One97 Communications Limited    3.8   \n",
       "9                                              EY    3.8   \n",
       "\n",
       "  No of days ago job posted  \n",
       "0                 2-7 years  \n",
       "1                   2-7 Yrs  \n",
       "2                   2-7 Yrs  \n",
       "3                 10-20 Yrs  \n",
       "4                  8-10 Yrs  \n",
       "5                  7-12 Yrs  \n",
       "6                  6-10 Yrs  \n",
       "7                  4-12 Yrs  \n",
       "8                   3-8 Yrs  \n",
       "9                   1-2 Yrs  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.ambitionbox.com/') #calling webdriver and getting into website  \n",
    "time.sleep(10)\n",
    "driver.find_element_by_xpath(\"//button[@class='modal__close-button']\").click() #Clicking popup close button\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a\").click() #clicking job button\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"//input[@class='input tt-input']\").send_keys('Data Scientist') #Input Job role in search field\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\").click() #clicking search button\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"//div[@title='Location']\").click() #Clicking on location filter\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\").send_keys('Noida') \n",
    "#Entering required input in location filter\n",
    "time.sleep(1)\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\").click() \n",
    "#Clicking for search of location\n",
    "time.sleep(1)\n",
    "company = driver.find_elements_by_xpath(\"//p[@class='company body-medium']\")\n",
    "Company = [i.text for i in company] # Scraping of company name data\n",
    "days = driver.find_elements_by_xpath(\"//div[@class='job-basic-info show-flex']\")\n",
    "Days = [i.text.split('\\n')[0] for i in days] # Scraping of No of days ago job posted data\n",
    "rating = driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "Rating = [i.text for i in rating] # Scraping of company rating data\n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Company name':Company[0:10], 'Rating':Rating[0:10], 'No of days ago job posted':Days[0:10]}) #Saving scraped data into a dataframe\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0eb287",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of ‚ÄúSearch Job Profile‚Äù enters ‚ÄúData Scientist‚Äù and then click on ‚ÄúData Scientist‚Äù.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6afc17e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>No. of salaries recorded</th>\n",
       "      <th>Work experience</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Minimum salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>3-4 yrs</td>\n",
       "      <td>‚Çπ 32.3L</td>\n",
       "      <td>‚Çπ 25.0L</td>\n",
       "      <td>‚Çπ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 57 salaries</td>\n",
       "      <td>2-4 yrs</td>\n",
       "      <td>‚Çπ 19.9L</td>\n",
       "      <td>‚Çπ 15.0L</td>\n",
       "      <td>‚Çπ 26.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>2-4 yrs</td>\n",
       "      <td>‚Çπ 16.4L</td>\n",
       "      <td>‚Çπ 11.0L</td>\n",
       "      <td>‚Çπ 22.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 34 salaries</td>\n",
       "      <td>1-2 yrs</td>\n",
       "      <td>‚Çπ 15.8L</td>\n",
       "      <td>‚Çπ 11.0L</td>\n",
       "      <td>‚Çπ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 115 salaries</td>\n",
       "      <td>2-4 yrs</td>\n",
       "      <td>‚Çπ 15.4L</td>\n",
       "      <td>‚Çπ 9.0L</td>\n",
       "      <td>‚Çπ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 68 salaries</td>\n",
       "      <td>2-4 yrs</td>\n",
       "      <td>‚Çπ 14.7L</td>\n",
       "      <td>‚Çπ 9.0L</td>\n",
       "      <td>‚Çπ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>1 yr</td>\n",
       "      <td>‚Çπ 14.7L</td>\n",
       "      <td>‚Çπ 12.7L</td>\n",
       "      <td>‚Çπ 19.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>4 yrs</td>\n",
       "      <td>‚Çπ 14.5L</td>\n",
       "      <td>‚Çπ 11.0L</td>\n",
       "      <td>‚Çπ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>4 yrs</td>\n",
       "      <td>‚Çπ 14.0L</td>\n",
       "      <td>‚Çπ 12.0L</td>\n",
       "      <td>‚Çπ 18.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>3 yrs</td>\n",
       "      <td>‚Çπ 13.9L</td>\n",
       "      <td>‚Çπ 8.8L</td>\n",
       "      <td>‚Çπ 17.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Company No. of salaries recorded Work experience  \\\n",
       "0                     Walmart     based on 23 salaries        3-4 yrs    \n",
       "1                    Ab Inbev     based on 57 salaries        2-4 yrs    \n",
       "2                       Optum     based on 49 salaries        2-4 yrs    \n",
       "3                          ZS     based on 34 salaries        1-2 yrs    \n",
       "4           Fractal Analytics    based on 115 salaries        2-4 yrs    \n",
       "5             Tiger Analytics     based on 68 salaries        2-4 yrs    \n",
       "6           Sigmoid Analytics     based on 10 salaries           1 yr    \n",
       "7  Legato Health Technologies     based on 11 salaries          4 yrs    \n",
       "8                        HSBC     based on 10 salaries          4 yrs    \n",
       "9                    Tredence     based on 14 salaries          3 yrs    \n",
       "\n",
       "  Average salary Minimum salary Maximum salary  \n",
       "0        ‚Çπ 32.3L        ‚Çπ 25.0L        ‚Çπ 45.0L  \n",
       "1        ‚Çπ 19.9L        ‚Çπ 15.0L        ‚Çπ 26.0L  \n",
       "2        ‚Çπ 16.4L        ‚Çπ 11.0L        ‚Çπ 22.6L  \n",
       "3        ‚Çπ 15.8L        ‚Çπ 11.0L        ‚Çπ 22.0L  \n",
       "4        ‚Çπ 15.4L         ‚Çπ 9.0L        ‚Çπ 23.0L  \n",
       "5        ‚Çπ 14.7L         ‚Çπ 9.0L        ‚Çπ 20.0L  \n",
       "6        ‚Çπ 14.7L        ‚Çπ 12.7L        ‚Çπ 19.7L  \n",
       "7        ‚Çπ 14.5L        ‚Çπ 11.0L        ‚Çπ 20.0L  \n",
       "8        ‚Çπ 14.0L        ‚Çπ 12.0L        ‚Çπ 18.0L  \n",
       "9        ‚Çπ 13.9L         ‚Çπ 8.8L        ‚Çπ 17.5L  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.ambitionbox.com/') #calling webdriver and getting into website  \n",
    "time.sleep(10)\n",
    "driver.find_element_by_xpath(\"//button[@class='modal__close-button']\").click() #Clicking popup close button\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span\").click() #clicking on salaries button\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/p\").click() #Sub selection\n",
    "time.sleep(2)\n",
    "driver.find_element_by_id(\"jobProfileSearchbox\").send_keys(\"Data Scientist\") #Searching input for job profile\n",
    "time.sleep(1)\n",
    "driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p').click() \n",
    "#Selecting suggestion from drop list\n",
    "time.sleep(1)\n",
    "Company = []\n",
    "Record = []\n",
    "Experience = []\n",
    "Min_salary = []\n",
    "Max_salary = []\n",
    "Avg_salary = []\n",
    "company = driver.find_elements_by_xpath(\"//div[@class='company-info']/a\")\n",
    "Company = [i.text.split('\\n')[0] for i in company] # Scraping company name data\n",
    "record = driver.find_elements_by_xpath(\"//div[@class='sbold-list-header']\")\n",
    "Record = [i.text.split('experience ')[1].replace('(','').replace(')','') for i in record] #Scraping ata of no of salaries recorded\n",
    "Experience = [i.text.split('experience ')[0] for i in record] #Scraping experience data\n",
    "salary = driver.find_elements_by_xpath(\"//div[@class='salary-values']\")\n",
    "Min_salary = [i.text.split('\\n')[0] for i in salary] # Scraping min salary data\n",
    "Max_salary = [i.text.split('\\n')[1] for i in salary] # Scraping max salary data\n",
    "avg = driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
    "Avg_salary = [i.text for i in avg] # Scraping min salary data\n",
    "driver.close() #Closing the web browser after scraping\n",
    "Data = pd.DataFrame({'Company':Company, 'No. of salaries recorded':Record, 'Work experience':Experience, 'Average salary':Avg_salary, 'Minimum salary':Min_salary, 'Maximum salary':Max_salary})\n",
    "#saving data as dataframe\n",
    "Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
