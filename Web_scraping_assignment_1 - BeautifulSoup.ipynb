{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca88832",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "70b5764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests                                                       \n",
    "\n",
    "\n",
    "def header_tags(url):                                                     # defining the function with url as parameter\n",
    "    \n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage\n",
    "    heading = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])         # scrape required data\n",
    "    for i in heading:             \n",
    "        print(i,\"\\n\")                                                     # display scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed3d3a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1> \n",
      "\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2> \n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2> \n",
      "\n",
      "<h2>Navigation menu</h2> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3> \n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3> \n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "header_tags('https://en.wikipedia.org/wiki/Main_Page')                    # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d05aa0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903bff36",
   "metadata": {},
   "source": [
    "2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "590e0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_100(url):                                                         # defining a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage\n",
    "\n",
    "    scraped_movies = soup.find_all(\"td\", class_ = \"titleColumn\")          # scrape movie title data\n",
    "    Title = []\n",
    "    for i in scraped_movies:\n",
    "        i = i.text.replace('\\n','')\n",
    "        i = i.rstrip(i[-6:])\n",
    "        head,sep,tail = i.partition('.')\n",
    "        Title.append(tail.strip())\n",
    "    Title = Title[:100]                                                  # selecting top 100\n",
    "\n",
    "    scraped_year = soup.find_all(\"span\", class_ = \"secondaryInfo\")       # scrape movie year data\n",
    "    Year = []\n",
    "    for i in scraped_year:\n",
    "        Year.append(i.text.replace('(','').replace(')', ''))\n",
    "    Year = Year[:100]                                                    # selecting top 100\n",
    "    \n",
    "    scraped_rating = soup.find_all(\"td\", class_ = \"ratingColumn imdbRating\") # scrape movie rating data\n",
    "    Rating = []\n",
    "    for i in scraped_rating:\n",
    "        Rating.append(i.text.replace('\\n',''))\n",
    "    Rating = Rating[:100]                                                # selecting top 100\n",
    "\n",
    "    Top_100 = pd.DataFrame({\"Movie Name\" : Title, \"Rating\" : Rating, \"Year of release\" : Year}) # dataframe of scraped data\n",
    "    return(Top_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "03ff87fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Movie Name Rating Year of release\n",
       "0            The Shawshank Redemption    9.2            1994\n",
       "1                       The Godfather    9.2            1972\n",
       "2                     The Dark Knight    9.0            2008\n",
       "3               The Godfather Part II    9.0            1974\n",
       "4                        12 Angry Men    8.9            1957\n",
       "..                                ...    ...             ...\n",
       "95                             Jagten    8.3            2012\n",
       "96  M - Eine Stadt sucht einen Mörder    8.3            1931\n",
       "97                 North by Northwest    8.3            1959\n",
       "98                       Idi i smotri    8.2            1985\n",
       "99                            Vertigo    8.2            1958\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100('https://www.imdb.com/chart/top/')                                 # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a70c79",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a1713",
   "metadata": {},
   "source": [
    "3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8915fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_100_Indian(url):                                                         # defining a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage\n",
    "\n",
    "    scraped_movies = soup.find_all(\"td\", class_ = \"titleColumn\")          # scrape movie title data\n",
    "    Title = []\n",
    "    for i in scraped_movies:\n",
    "        i = i.text.replace('\\n','')\n",
    "        i = i.rstrip(i[-6:])\n",
    "        head,sep,tail = i.partition('.')\n",
    "        Title.append(tail.strip())\n",
    "    Title = Title[:100]                                                  # selecting top 100\n",
    "\n",
    "    scraped_year = soup.find_all(\"span\", class_ = \"secondaryInfo\")       # scrape movie year data\n",
    "    Year = []\n",
    "    for i in scraped_year:\n",
    "        Year.append(i.text.replace('(','').replace(')', ''))\n",
    "    Year = Year[:100]                                                    # selecting top 100\n",
    "    \n",
    "    scraped_rating = soup.find_all(\"td\", class_ = \"ratingColumn imdbRating\") # scrape movie rating data\n",
    "    Rating = []\n",
    "    for i in scraped_rating:\n",
    "        Rating.append(i.text.replace('\\n',''))\n",
    "    Rating = Rating[:100]                                                # selecting top 100\n",
    "\n",
    "    Top_100 = pd.DataFrame({\"Movie Name\" : Title, \"Rating\" : Rating, \"Year of release\" : Year}) # dataframe of scraped data\n",
    "    return(Top_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ff0f9d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Baasha</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Movie Name Rating Year of release\n",
       "0    Rocketry: The Nambi Effect    8.5            2022\n",
       "1                    Anbe Sivam    8.4            2003\n",
       "2                       Golmaal    8.4            1979\n",
       "3                       Nayakan    8.4            1987\n",
       "4                      Jai Bhim    8.4            2021\n",
       "..                          ...    ...             ...\n",
       "95              Rang De Basanti    8.0            2006\n",
       "96  Baahubali 2: The Conclusion    8.0            2017\n",
       "97                       Baasha    8.0            1995\n",
       "98                       Masaan    8.0            2015\n",
       "99                    Virumandi    8.0            2004\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_Indian('https://www.imdb.com/india/top-rated-indian-movies/')   # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c53cf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e22fcd",
   "metadata": {},
   "source": [
    "4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1734f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def President_India(url):                                                 # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage\n",
    "\n",
    "    names = soup.find_all(\"div\", class_ = \"presidentListing\")             # scrape President name data\n",
    "    Name = []\n",
    "    for i in names:\n",
    "        i = i.text\n",
    "        head,sep,tail = i.partition('(')\n",
    "        Name.append(head.replace('\\n',''))\n",
    "\n",
    "    term = soup.find_all(\"div\", class_ = \"presidentListing\")              # scrape Term of Office data\n",
    "    Term = []\n",
    "    for i in term:\n",
    "        i = i.text\n",
    "        head,sep,tail = i.partition('Term of Office: ')\n",
    "        i = tail\n",
    "        head,sep,tail = i.partition('\\n')\n",
    "        Term.append(head)\n",
    "        \n",
    "    President = pd.DataFrame({\"Name\" : Name, \"Term of Office\" : Term})   # dataframe of scraped data\n",
    "    return(President)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "169e42e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "President_India(\"https://presidentofindia.nic.in/former-presidents.htm\") # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf8224c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47833ce",
   "metadata": {},
   "source": [
    "5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "85bd1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_odi_men(url):                                                     # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "    \n",
    "    team = soup.find_all('span', class_ = 'u-hide-phablet')               # scrape team name data\n",
    "    Team = []\n",
    "    for i in team:\n",
    "        i = i.get_text()\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "\n",
    "    Top_team_r = soup.find('td', class_ = 'rankings-block__banner--rating u-text-right').text.replace('\\n','').replace(' ', '')\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')  # scrape team rating data\n",
    "    Rating = [Top_team_r]\n",
    "    for i in rating:\n",
    "        i = i.get_text()\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    match_point = soup.find_all('td', class_ = 'table-body__cell u-center-text') # scrape matches played along with points data\n",
    "    Match_Point = []\n",
    "    for i in match_point:\n",
    "        i = i.get_text()\n",
    "        Match_Point.append(i)\n",
    "\n",
    "    Top_team_m = soup.find('td', class_ = 'rankings-block__banner--matches').text\n",
    "    Top_team_p = soup.find('td', class_ = 'rankings-block__banner--points').text\n",
    "    Match = [Top_team_m] \n",
    "    Point = [Top_team_p]\n",
    "    i=0  \n",
    "    j=1\n",
    "    while i<17:                                                           # seggregating matches played and ratings data\n",
    "        Match.append(Match_Point[i])\n",
    "        Point.append(Match_Point[j])\n",
    "        i = i+2 \n",
    "        j= j+2\n",
    "        \n",
    "    Top_odi = pd.DataFrame({\"Team Name\" : Team, \"Rating\" : Rating, \"Matches\" : Match, \"Point\" : Point}) # dataframe of scraped data\n",
    "    return(Top_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "52efb786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>2,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>119</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>111</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>107</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>101</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>71</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Rating Matches  Point\n",
       "0   New Zealand    124      19  2,355\n",
       "1       England    119      27  3,226\n",
       "2         India    111      31  3,447\n",
       "3      Pakistan    107      22  2,354\n",
       "4     Australia    101      23  2,325\n",
       "5  South Africa    101      21  2,111\n",
       "6    Bangladesh     92      30  2,753\n",
       "7     Sri Lanka     92      29  2,658\n",
       "8   West Indies     71      41  2,902\n",
       "9   Afghanistan     69      18  1,238"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_men(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\") # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54676f2c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7211f",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a0209fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                            # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_odi_batsmen(url):                                                 # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell name')                     # scraping top player name data\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')    # scraping top player rating data\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')                   # scraping top player team data\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','').split(' ')[0]\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})           # dataframe of scraped data\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4139dde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Team Rating\n",
       "0             Babar Azam  PAK    890\n",
       "1  Rassie van der Dussen   SA    789\n",
       "2        Quinton de Kock   SA    784\n",
       "3            Imam-ul-Haq  PAK    779\n",
       "4            Virat Kohli  IND    744\n",
       "5           Rohit Sharma  IND    740\n",
       "6           David Warner  AUS    737\n",
       "7         Jonny Bairstow  ENG    732\n",
       "8            Ross Taylor   NZ    722\n",
       "9            Aaron Finch  AUS    715"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_batsmen(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\") # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b1492",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0bdc5",
   "metadata": {},
   "source": [
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "840c3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                            # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_odi_bowlers(url):                                                 # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name') # scraping top player name data\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell rating')                 # scraping top player rating data\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')                   # scraping top player team data\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})           # dataframe of scraped data\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8c97767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                    Team Rating\n",
       "0        Trent Boult  NZ                        720\n",
       "1     Josh Hazlewood                     AUS    679\n",
       "2   Mujeeb Ur Rahman                     AFG    676\n",
       "3     Jasprit Bumrah                     IND    662\n",
       "4     Shaheen Afridi                     PAK    661\n",
       "5      Mohammad Nabi                     AFG    657\n",
       "6       Mehedi Hasan                     BAN    655\n",
       "7        Rashid Khan                     AFG    651\n",
       "8         Matt Henry                      NZ    644\n",
       "9  Mustafizur Rahman                     BAN    640"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_bowlers(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\") # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f9cc0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4010c",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ada99fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_odi_wteam(url):                                                   # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "    \n",
    "    team = soup.find_all('span', class_ = 'u-hide-phablet')               # scrape team name data\n",
    "    Team = []\n",
    "    for i in team:\n",
    "        i = i.get_text()\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "\n",
    "    Top_team_r = soup.find('td', class_ = 'rankings-block__banner--rating u-text-right').text.replace('\\n','').replace(' ', '')\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')  # scrape team rating data\n",
    "    Rating = [Top_team_r]\n",
    "    for i in rating:\n",
    "        i = i.get_text()\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    match_point = soup.find_all('td', class_ = 'table-body__cell u-center-text') # scrape matches played along with points data\n",
    "    Match_Point = []\n",
    "    for i in match_point:\n",
    "        i = i.get_text()\n",
    "        Match_Point.append(i)\n",
    "\n",
    "    Top_team_m = soup.find('td', class_ = 'rankings-block__banner--matches').text\n",
    "    Top_team_p = soup.find('td', class_ = 'rankings-block__banner--points').text\n",
    "    Match = [Top_team_m] \n",
    "    Point = [Top_team_p]\n",
    "    i=0  \n",
    "    j=1\n",
    "    while i<17:                                                           # seggregating matches played and ratings data\n",
    "        Match.append(Match_Point[i])\n",
    "        Point.append(Match_Point[j])\n",
    "        i = i+2 \n",
    "        j= j+2\n",
    "        \n",
    "    Top_odi = pd.DataFrame({\"Team Name\" : Team, \"Rating\" : Rating, \"Matches\" : Match, \"Point\" : Point}) # dataframe of scraped data\n",
    "    return(Top_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e7c66c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>167</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>101</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>97</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Rating Matches  Point\n",
       "0     Australia    167      29  4,837\n",
       "1       England    123      33  4,046\n",
       "2  South Africa    119      35  4,157\n",
       "3         India    101      32  3,219\n",
       "4   New Zealand     97      31  3,019\n",
       "5   West Indies     92      30  2,768\n",
       "6    Bangladesh     78      12    930\n",
       "7      Pakistan     65      30  1,962\n",
       "8       Ireland     45       9    405\n",
       "9     Sri Lanka     45      11    495"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_wteam(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\") # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a3280",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b809e",
   "metadata": {},
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                            # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_odi_wbat(url):                                                    # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name') # scraping top player name data\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell rating')                 # scraping top player rating data\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')                   # scraping top player team data\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})           # dataframe of scraped data\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_odi_wbat('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting') # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411af56",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                            # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def top_odi_wbowl(url):                                                    # definiing a function with url as parameter\n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "\n",
    "    name = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name') # scraping top player name data\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating = soup.find_all('td', class_ = 'table-body__cell rating')                 # scraping top player rating data\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team = soup.find_all('span', class_ = 'table-body__logo-text')                   # scraping top player team data\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Name':Name, 'Team':Team, 'Rating':Rating})           # dataframe of scraped data\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_odi_wbowl('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling') # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622bb2b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550022ce",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def news(url):                                                            # definiing a function with url as parameter \n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "\n",
    "    title = soup.find_all('a', class_ ='LatestNews-headline')             # scraping news headline data\n",
    "    Title = []\n",
    "    for i in title:\n",
    "        Title.append(i.text) \n",
    "\n",
    "    time = soup.find_all('time', class_ ='LatestNews-timestamp')          # scraping news time data\n",
    "    Time = []\n",
    "    for i in time:\n",
    "        Time.append(i.text) \n",
    "\n",
    "    link = soup.find_all('div', class_='LatestNews-headlineWrapper')      # scraping news link data\n",
    "    Link = []\n",
    "    for i in link:\n",
    "        head, sep, tail = str(i).partition('\" title=')\n",
    "        head, sep, tail = head.partition('a class=\"LatestNews-headline\" href=\"')\n",
    "        Link.append(tail)\n",
    "\n",
    "    DataFrame = pd.DataFrame({'News title':Title,'Time stamp':Time,'Link':Link}) # Dataframe of scraped data\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news('https://www.cnbc.com/world/?region=world')              # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e828774",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e875f",
   "metadata": {},
   "source": [
    "8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f77f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                               # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def paper(url):                                                             # defining a function with url as parameter \n",
    "    page = requests.get(url)                                                # get URL\n",
    "    soup = BeautifulSoup(page.content)                                      # scrape webpage content\n",
    "\n",
    "    title = soup.find_all('h2', class_ ='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR') # scraping title data\n",
    "    Title = []\n",
    "    for i in title:\n",
    "        Title.append(i.text) \n",
    "\n",
    "    author = soup.find_all('span', class_ ='sc-1w3fpd7-0 pgLAT')            # scraping paper author data\n",
    "    Author = []\n",
    "    for i in author:\n",
    "        Author.append(i.text) \n",
    "\n",
    "    date = soup.find_all('span', class_ ='sc-1thf9ly-2 bKddwo')             # scraping paper published date data\n",
    "    Date = []\n",
    "    for i in date:\n",
    "        Date.append(i.text) \n",
    "\n",
    "    link = soup.find_all('a', class_ ='sc-5smygv-0 nrDZj')                  # scraping publication link data\n",
    "    Link = []\n",
    "    for i in link:\n",
    "        Link.append(i['href'])\n",
    "        \n",
    "    DataFrame = pd.DataFrame({'Paper title':Title,'Author':Author,'Publication date':Date,'Link':Link}) # Dataframe of scraped data\n",
    "    return(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles') # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbc831",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a12f6c",
   "metadata": {},
   "source": [
    "9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                             # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def restuarant(url):                                                      # defining a function with url as parameter \n",
    "    page = requests.get(url)                                              # get URL\n",
    "    soup = BeautifulSoup(page.content)                                    # scrape webpage content\n",
    "    \n",
    "    Restuarant_name = []                                                  # Scrape Restuarant name and location data\n",
    "    Location = []\n",
    "    for i in soup.find_all('div', class_ = 'restnt-info cursor'):\n",
    "        Restuarant_name.append(i.a.text)\n",
    "        Location.append(i.div.text)\n",
    "\n",
    "    Cuisine = []                                                          # Scrape Restuarant cuisine data\n",
    "    for i in soup.find_all('span', class_ = 'double-line-ellipsis'):\n",
    "        head, sep, tail = i.text.partition('|')\n",
    "        Cuisine.append(tail)\n",
    "\n",
    "    Image_url = []                                                        # Scrape Restuarant image url data\n",
    "    for i in soup.find_all('img', class_ = 'no-img'):\n",
    "        Image_url.append(i['data-src'])\n",
    "\n",
    "    Rating = []                                                           # Scrape Restuarant rating data\n",
    "    for i in soup.find_all('div', class_ = 'restnt-rating rating-4'):\n",
    "        Rating.append(i.text)\n",
    "\n",
    "    DataFrame = pd.DataFrame({'Restuarant_name':Restuarant_name, 'Cuisine':Cuisine, 'Location':Location, 'Rating':Rating, 'Image_url':Image_url})\n",
    "    return(DataFrame)                                                     # DataFrame of scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "restuarant('https://www.dineout.co.in/delhi-restaurants/welcome-back') # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4b07f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99113586",
   "metadata": {},
   "source": [
    "10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank\n",
    "ii) Publication\n",
    "iii) h5-index\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                                 # import required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def paper(url):                                                               # defining a function with url as parameter \n",
    "    page = requests.get(url)                                                  # get URL\n",
    "    soup = BeautifulSoup(page.content)                                        # scrape webpage content\n",
    "\n",
    "    rank = soup.find_all('td', class_ ='gsc_mvt_p')                           # scraping rank data\n",
    "    Rank = []\n",
    "    for i in rank:\n",
    "        Rank.append(i.text) \n",
    "\n",
    "    publication = soup.find_all('td', class_ ='gsc_mvt_t')                    # scraping publication data\n",
    "    Publication = []\n",
    "    for i in publication:\n",
    "        Publication.append(i.text) \n",
    "\n",
    "    h5_index = soup.find_all('a', class_ ='gs_ibl gsc_mp_anchor')             # scraping h5_index data\n",
    "    H5_index = []\n",
    "    for i in h5_index:\n",
    "        H5_index.append(i.text) \n",
    "\n",
    "    h5_median = soup.find_all('span', class_ ='gs_ibl gsc_mp_anchor')         # scraping h5_median data\n",
    "    H5_median = []\n",
    "    for i in h5_median:\n",
    "        H5_median.append(i.text)\n",
    "                                                        \n",
    "    DataFrame = pd.DataFrame({'Rank':Rank,'Publication':Publication,'h5_index':H5_index,'h5_median':H5_median})\n",
    "    return(DataFrame)                                                         # Dataframe of scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper('https://scholar.google.com/citations?view_op=top_venues&hl=en') # calling the function by passing url as a parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a44e4",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
